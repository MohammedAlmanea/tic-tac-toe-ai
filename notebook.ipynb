{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tictactoe import *\n",
    "from minimax import *\n",
    "from alphabeta import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content:\n",
    "* Introduction\n",
    "\n",
    "* Tic-Tac-Toe\n",
    "\n",
    "* Mini-Max Algorithm\n",
    "\n",
    "* Alpha-Beta Pruning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adversarial Search is a problem in which two or more agentâ€™s goals conflict,\n",
    "it is one of the most significant fields in AI and to solve this problem we are going to discus using Min-Max and Alpha-Beta algorithms and we are going to implement them on the game tic-tac-toe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tic-Tac-Toe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tic-tac-toe](https://e7.pngegg.com/pngimages/821/182/png-clipart-3d-tic-tac-toe-tic-tac-toe-tictactoe-tic-tac-toe-android-3d-tic-tac-toe-tictactoe-thumbnail.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\t**2** players\n",
    "\n",
    "*\t**X** and **O**\n",
    "\n",
    "*\tGrid size of the board is **3x3**\n",
    "\n",
    "*\tGoal: the goal is for a player to mark **three consecutive marks either horizontally, vertically or diagonally.**\n",
    "\n",
    "*   Rules: player 1 starts and place the **X** mark on one of the squares then player 2 place the **O** mark on one of the squares until either of them      \n",
    "achieve the goal or the board has no more squares to be filled in which the game would be a draw.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%psource tictactoe.Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The upper bound of state space in tic-tac-toe:\n",
    "There are 3 states for each square and a total of 9 squares which mean that there are **3^9=19683** states including illegal states. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min-Max Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen the state space for tic-tac-toe is 19683 possible states it is possible to brute force it and search for the perfect move each time with tic-tac-toe, but it would be inefficient however for nontrivial games that practice is impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Min-Max algorithm:\n",
    "Min-Max is an algorithm applies search to a low tree depth using the appropriate heuristic and simple evaluation function.\n",
    "The Min-Max algorithm evaluates the potential moves every turn and choosing what appears to be the best move each turn.\n",
    "Depth-first search Min-Max has **O(b^m)** time complexity and **O(b^m)** space complexity.\n",
    "#### Evaluation function:\n",
    "* **f(n)=1** means Iâ€™m winning in position n.\n",
    "* **f(n)=0** means that we are tied at position n. \n",
    "* **f(n)=-1** mean that you are winning at position n.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha-Beta Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha-Beta is an improved Min-Max it stops evaluating moves when it makes sure that it's worse than previously examined move it gives the same output as a Min-Max algorithm but it cutâ€™s off branches that canâ€™t affect the final decision and therefore affect the performance dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **ð›¼ :** Represent best explored option for player Max.\n",
    "* **ð›½ :** Represent best explored option for player Min."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially **ð›¼ = -âˆž** and **ð›½ = âˆž** and each time a value bigger than **ð›¼** appears **ð›¼ = new** value and the opposite for **ð›½**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cutoff search if **Î± >= Î²** or **Î² <= Î±**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run minimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run alphabeta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
